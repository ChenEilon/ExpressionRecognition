{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test syntax passed:)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "faceDet = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "faceDet_two = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"haarcascade_frontalface_alt_tree.xml\")\n",
    "\n",
    "REF_POINTS = [4, 14, 18, 20, 22, 23, 25, 27, 28, 31, 32, 36, 37, 38, 40, 42, 43, 45, 46, 47, 49, 51, 52, 53, 61, 63, 65, 67]\n",
    "#EMOTIONS = [\"neutral\",  \"happy\", \"sadness\", \"surprise\",  \"fear\", \"disgust\", \"anger\", \"contempt\"] #Define emotions\n",
    "EMOTIONS = [\"neutral\",  \"happy\", \"sadness\", \"surprise\",  \"fear\", \"disgust\", \"anger\"]\n",
    "\n",
    "#######################################################################################\n",
    "##############                   Math and transformations                  ############\n",
    "#######################################################################################\n",
    "def squared_distance(x,y):\n",
    "    return (x[0]-y[0])**2+(x[1]-y[1])**2\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "    \"\"\" take a bounding predicted by dlib and convert it\n",
    "     to the format (x, y, w, h) as we would normally do\n",
    "     with OpenCV\n",
    "     *from web tutorial*\"\"\"\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    return (x, y, w, h) # return a tuple of (x, y, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    \"\"\"\n",
    "    *from web tutorial*\n",
    "    \"\"\"\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords\n",
    "\n",
    "def nparray_to_pandas_images(faces_68_landmarks):\n",
    "    \"\"\"\n",
    "    input - nparray of numpy array (list of images numpy array, which contains 68 cords(tuple))\n",
    "    output - pandas dataframe of data\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_records(faces_68_landmarks)\n",
    "    return df\n",
    "    \n",
    "def dataset_from_ck(inputFolderCKData):\n",
    "    print(\"CK+ dataset preparation...\")\n",
    "    #create train_data and train_lbls\n",
    "    print(\"analyzing {0:s}...\".format(EMOTIONS[0]))\n",
    "    facial_landmarks_data = extract_dlib_facial_points(inputFolderCKData + \"\\\\\" + EMOTIONS[0])\n",
    "    emotion_len = facial_landmarks_data.shape[0]\n",
    "    train_lbls = [0 for i in range(emotion_len)]\n",
    "    for e in range(1,len(EMOTIONS)):\n",
    "        print(\"analyzing {0:s}...\".format(EMOTIONS[e]))\n",
    "        tmp = extract_dlib_facial_points(inputFolderCKData + \"\\\\\" + EMOTIONS[e])\n",
    "        facial_landmarks_data = np.concatenate((facial_landmarks_data, tmp))\n",
    "        train_lbls += [e for i in range(facial_landmarks_data.shape[0]-emotion_len)]\n",
    "        emotion_len = facial_landmarks_data.shape[0]\n",
    "    print(\"CK+ dataset ready!...\")\n",
    "    return (facial_landmarks_data, train_lbls)\n",
    "\n",
    "def save_plt_scores(params, nameP, scores, nameScores, title, log_scale=True):\n",
    "    fig = plt.figure()\n",
    "    plt.grid(True)\n",
    "    #axes = plt.gca()\n",
    "    if log_scale:\n",
    "        plt.semilogx()\n",
    "    plt.plot(params, scores)\n",
    "    plt.axis([min(params) , max(params) , min(scores) - 0.01, max(scores) + 0.01])\n",
    "    plt.ylabel(nameScores)\n",
    "    plt.xlabel(nameP)\n",
    "    plt.title(title)\n",
    "    #plt.show()\n",
    "    fig.savefig(title+'.png')\n",
    "\n",
    "def dataset_from_affectnet(trainingCsvPath):\n",
    "    \"\"\"\n",
    "    problem with affectnet landmarks...\n",
    "    \"\"\"\n",
    "    data_df = pd.read_csv(trainingCsvPath)\n",
    "    df_filtered = data_df.query('expression<8')\n",
    "    landmarks = (df_filtered[['facial_landmarks']].values).flatten()\n",
    "    labels = df_filtered[['expression']].values\n",
    "    facial_landmarks_data = [np.reshape(i.split(\";\"),(68,2)) for i in landmarks]\n",
    "    return (facial_landmarks_data, labels.flatten())\n",
    "\n",
    "    \n",
    "#######################################################################################\n",
    "##############                   Point Methods                             ############\n",
    "#######################################################################################\n",
    "\n",
    "def dot_matrix(point_arr):\n",
    "    \"\"\"\n",
    "    input - nparray of (x, y) points\n",
    "    output - an nxn matrix M where M[i, j] is the dot product of (xi, yi) and (xj, yj)\n",
    "    \"\"\"\n",
    "    dot_m = np.ndarray(shape=(len(point_arr), len(point_arr)), dtype=int)\n",
    "    for i in range(len(point_arr)):\n",
    "        for j in range(i+1):\n",
    "            dot_m[i, j] = np.dot(point_arr[i], point_arr[j])\n",
    "            dot_m[j, i] = dot_m[i, j]\n",
    "    return dot_m\n",
    "\n",
    "def dist_matrix(dot_m):\n",
    "    \"\"\"\n",
    "    input - a dot matrix (output of dot_matrix method)\n",
    "    output - an nxn matrix M where M[i, j] is the distance between (xi, yi) and (xj, yj)\n",
    "    \"\"\"\n",
    "    dist_m = np.ndarray(shape=dot_m.shape, dtype=float)\n",
    "    for i in range(dist_m.shape[0]):\n",
    "        dist_m[i, i] = 0\n",
    "        for j in range(i):\n",
    "            dist_m[i, j] = np.sqrt(dot_m[i, i] - 2*dot_m[i, j] + dot_m[j, j])\n",
    "            dist_m[j, i] = dist_m[i, j]\n",
    "    return dist_m\n",
    "\n",
    "def dist_array(dist_m):\n",
    "    \"\"\"\n",
    "    input - a distance matrix (output of dist_matrix method)\n",
    "    output - an array of all of the distances, w/o duplicates\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    for i in range(dist_m.shape[0]):\n",
    "        for j in range(i):\n",
    "            dists.append(dist_m[i, j])\n",
    "    return np.array(dists)\n",
    "\n",
    "def angle_array(dot_m, dist_m):\n",
    "    \"\"\"\n",
    "    input - a dot matrix (output of dot_matrix method), a distance matrix (output of dist_matrix method)\n",
    "    output - an array of all of the angles, w/o duplicates\n",
    "    \"\"\"\n",
    "    angles = []\n",
    "    for i in range(dot_m.shape[0]):\n",
    "        for j in range(i):\n",
    "            for k in range(j):\n",
    "                #TODO change solution to devision by 0\n",
    "                if not (dist_m[i, j] * dist_m[j, k] * dist_m[i, k]):\n",
    "                    angles.append(-1)\n",
    "                    angles.append(-1)\n",
    "                    # angles.append(-1)\n",
    "                else:\n",
    "                    angles.append(np.arccos(round(\n",
    "                        (dot_m[i, k] - dot_m[i, j] - dot_m[j, k] + dot_m[j, j]) / (dist_m[i, j] * dist_m[j, k]),\n",
    "                        15)))\n",
    "                    angles.append(np.arccos(round(\n",
    "                        (dot_m[i, j] - dot_m[i, k] - dot_m[k, j] + dot_m[k, k]) / (dist_m[i, k] * dist_m[k, j]),\n",
    "                        15)))\n",
    "                    # angles.append(np.pi - angles[-1] - angles[-2])\n",
    "    return np.array(angles)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "##############            Detecting face and face landmarks                ############\n",
    "#######################################################################################\n",
    "    \n",
    "def detect_faces_CascadeClassifier(inputFolder,outputFolder):\n",
    "    \"\"\"\n",
    "    foreach image in inputFolder: convert to gray scale, search faces with cv2.CascadeClassifier, cut, resize and save face in outputFolder\n",
    "    *from web tutorial*\n",
    "    *not used*\n",
    "    \"\"\"\n",
    "    files = glob.glob(\"%s\\\\*\"%inputFolder) #Get list of all images in inputFolder\n",
    "    filenumber = 0\n",
    "    for f in files:\n",
    "        frame = cv2.imread(f) #Open image\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale\n",
    "        #Detect face using 4 different classifiers\n",
    "        face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "        if len(face) == 1:\n",
    "            facefeatures = face\n",
    "        elif len(face_two) == 1:\n",
    "            facefeatures = face_two\n",
    "        elif len(face_three) == 1:\n",
    "            facefeatures = face_three\n",
    "        elif len(face_four) == 1:\n",
    "            facefeatures = face_four\n",
    "        else:\n",
    "            facefeatures = \"\"\n",
    "        #Cut and save face\n",
    "        for (x, y, w, h) in facefeatures: #get coordinates and size of rectangle containing face\n",
    "            print (\"face found in file: \", f)\n",
    "            gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "            try:\n",
    "                out = cv2.resize(gray, (350, 350)) #Resize face so all images have same size\n",
    "                cv2.imwrite(\"%s\\\\%s.jpg\" %(outputFolder, filenumber), out) #Write image\n",
    "            except:\n",
    "               pass #If error, pass file\n",
    "        filenumber += 1 #Increment image number\n",
    "\n",
    "def image_to_landmarks(image_path, detector, predictor):\n",
    "    \"\"\"assuming an image\"\"\"\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return []\n",
    "    image = imutils.resize(image, width=350)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    # determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "    if len(rects)==0:\n",
    "        return []\n",
    "    shape = predictor(gray, rects[0])\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    #faces_68_landmarks.append(shape)\n",
    "    return shape\n",
    "\n",
    "\n",
    "        \n",
    "def extract_dlib_facial_points(inputFolder):\n",
    "    \"\"\"\n",
    "    input - images folder name\n",
    "    output - ndarray of images facial landmarks \n",
    "    \"\"\"\n",
    "    wanted_landmarks = [i-1 for i in REF_POINTS]\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    files = glob.glob(\"%s\\\\*\"%inputFolder) #Get list of all images in inputFolder\n",
    "    faces_landmarks = []\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".png\") or f.lower().endswith(\".jpg\") or f.lower().endswith(\".jpeg\"): \n",
    "            shape = image_to_landmarks(f, detector, predictor)\n",
    "            faces_landmarks.append(shape[wanted_landmarks])\n",
    "    return np.array(faces_landmarks)\n",
    "                \n",
    "\n",
    "def sort_sample_affectnet(inputFolder, csvPathAffectnet, start=0, count=10000):\n",
    "    \"\"\"\n",
    "    csv: 'image_name', 'expression', '68_landmarks'\n",
    "    \"\"\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    data_df = pd.read_csv(csvPathAffectnet)\n",
    "    landmarks = []\n",
    "    # Gal's lines, do not touch!\n",
    "    # folders = glob.glob(inputFolder + \"\\\\*\") #Returns a list of all folders with participant numbers\n",
    "    # for folder in folders:\n",
    "    #     files = glob.glob(folder + \"\\\\*\")\n",
    "    #     for f in files:\n",
    "    #         shape = image_to_landmarks(f, detector, predictor)\n",
    "    #         shape = list(np.array(shape).flatten())\n",
    "    #         img_name = [(f.split(\"\\\\\"))[-1]]\n",
    "    #         landmarks.append(img_name + shape)\n",
    "    for i in range(start, start+count):\n",
    "        f = \"{0}\\\\{1}\\\\{2}\".format(inputFolder, data_df.loc[i, \"subDirectory\"], data_df.loc[i, \"filePath\"])\n",
    "        shape = image_to_landmarks(f, detector, predictor)\n",
    "        shape = list(np.array(shape).flatten())\n",
    "        img_name = [(f.split(\"\\\\\"))[-1]]\n",
    "        landmarks.append(img_name + shape)\n",
    "    cols = [\"filePath\"] + [\"x_{0:d}\".format(i//2) if i%2==0 else \"y_{0:d}\".format(i//2) for i in range(2, 69*2)]\n",
    "    landmarks_df = pd.DataFrame(landmarks, columns=cols, index=np.arange(start, start+count))\n",
    "    if start == 0:\n",
    "        data_df = data_df.merge(landmarks_df, on=\"filePath\", how=\"left\")\n",
    "        data_df.to_csv('affectnet_landmarks.csv', index=False)\n",
    "    else:\n",
    "        data_df.update(landmarks_df)\n",
    "        data_df.to_csv(csvPathAffectnet, index=False)\n",
    "\n",
    "def add_expression_dummies(features_df):\n",
    "    for i in range(len(EMOTIONS)):\n",
    "        features_df[\"is_{0:s}\".format(EMOTIONS[i])] = (features_df[\"expression\"] == i)\n",
    "    features_df.drop(\"expression\", axis=1, inplace=True)\n",
    "\n",
    "def csv_to_features(csvDirPath, maxRows=2000, filePrefix=\"affectnet_landmarks\"):\n",
    "    \"\"\"\n",
    "    in - csv from sort_sample_affectnet\n",
    "    out - features dataframe\n",
    "    \"\"\"\n",
    "    col_names = []\n",
    "    for i in REF_POINTS:\n",
    "        col_names.append(\"x_{0:d}\".format(i))\n",
    "        col_names.append(\"y_{0:d}\".format(i))\n",
    "    filenames = [entry.name for entry in os.scandir(csvDirPath) if entry.name.endswith(\".csv\") and entry.name.startswith(filePrefix)]\n",
    "    for f in filenames:\n",
    "        print(\"Processing {0}\".format(f))\n",
    "        data_df = pd.read_csv(os.path.join(csvDirPath, f))\n",
    "        df_filtered = data_df.query('expression<=7').dropna().iloc[:maxRows, :] #filter out non-faces\n",
    "        #ndarray of wanted landmarks (row per image)\n",
    "        images_df = df_filtered[col_names]\n",
    "        images_df = np.reshape(images_df.values.astype(int), (len(images_df), len(REF_POINTS), 2))\n",
    "        #extract features\n",
    "        features_df = extract_features_forall(images_df)\n",
    "        features_df[\"expression\"] = df_filtered[\"expression\"].values\n",
    "        add_expression_dummies(features_df)\n",
    "        features_df.to_csv(os.path.join(csvDirPath, \"features_{0}\".format(f)))\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "##############            Extract features and reducing dimensions         ############\n",
    "#######################################################################################\n",
    "\n",
    "def reduce_correlated_cols(df, threshold=0.95):\n",
    "    \"\"\"\n",
    "    input - df &threshold (if 1>|correlation|>threshold then dimension is reduced\n",
    "    output - reduced df\n",
    "    \"\"\"\n",
    "    corr = df.corr()\n",
    "    corr = corr * np.fromfunction(lambda i, j: i > j, corr.shape)\n",
    "    corr_cols = (corr > threshold).sum(axis=1)\n",
    "    corr_cols = corr_cols[corr_cols > 0].axes[0].tolist()\n",
    "    ret = df.drop(corr_cols, axis=1)\n",
    "    return ret\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"\n",
    "    input - nparray of facial landmarks (point (x,y))\n",
    "    output - nparray of features per image\n",
    "    \"\"\"\n",
    "    #distance features\n",
    "    dot_m = dot_matrix(image)\n",
    "    dist_m = dist_matrix(dot_m)\n",
    "    #dists = dist_array(dist_m)\n",
    "    #angles features\n",
    "    angles = angle_array(dot_m, dist_m)\n",
    "    #flatten and concat\n",
    "    #features_vector = np.concatenate((dists, angles))\n",
    "    return np.around(angles, decimals = 2)\n",
    "    \n",
    "def extract_features_forall(images):\n",
    "    \"\"\"\n",
    "    input - ndarray of images facial landmarks (for each image a 68 long nparry of points)\n",
    "    output - dataframe of images features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    cols = []\n",
    "    for image in images:\n",
    "        features.append(extract_features(image))\n",
    "    #cols = [\"dist_{1:d}_{0:d}\".format(REF_POINTS[i], REF_POINTS[j]) for i in range(len(REF_POINTS)) for j in range(i)]\n",
    "    for i in range(len(REF_POINTS)):\n",
    "        for j in range(i):\n",
    "            for k in range(j):\n",
    "                cols.append(\"angle_{2:d}_{1:d}_{0:d}\".format(REF_POINTS[i], REF_POINTS[j], REF_POINTS[k]))\n",
    "                cols.append(\"angle_{1:d}_{2:d}_{0:d}\".format(REF_POINTS[i], REF_POINTS[j], REF_POINTS[k]))\n",
    "                # cols.append(\"angle_{2:d}_{0:d}_{1:d}\".format(REF_POINTS[i], REF_POINTS[j], REF_POINTS[k]))\n",
    "    df = pd.DataFrame(features, columns=cols)\n",
    "    return df\n",
    "    \n",
    "def dimension_reduction_pca(df, components = 100):\n",
    "    \"\"\"\n",
    "    input - dataframe of features & wanted dimension of features\n",
    "    output - trained PCA\n",
    "    uses PCA from skylearn\n",
    "    \"\"\"\n",
    "    #Standardize the Data\n",
    "    features = list(df.columns.values)\n",
    "    # Separating out the features\n",
    "    x = df.loc[:, features].values\n",
    "    # Standardizing the features\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    #dim reduction\n",
    "    pca = PCA(components)\n",
    "    pca.fit_transform(x)\n",
    "    return pca\n",
    "    \n",
    "\n",
    "def prepare_balanced_data(csvPaths, portionCount, testPart = 0.1, m_random_state = 33):\n",
    "    assert testPart<=1\n",
    "    test_threshhold = int(portionCount*(testPart))\n",
    "    data_df_tmp = pd.read_csv(csvPaths[0])\n",
    "    data_df_tmp = shuffle(data_df_tmp, random_state=m_random_state)\n",
    "    data_df_test = data_df_tmp[:test_threshhold]\n",
    "    data_df_train = data_df_tmp[test_threshhold:]\n",
    "    for i in range(len(csvPaths)-1):\n",
    "        data_df_tmp = pd.read_csv(csvPaths[i+1])\n",
    "        data_df_tmp = data_df_tmp[:portionCount]\n",
    "        data_df_tmp = shuffle(data_df_tmp, random_state=m_random_state)\n",
    "        data_df_test = data_df_test.append(data_df_tmp[:test_threshhold])\n",
    "        data_df_train = data_df_train.append(data_df_tmp[test_threshhold:])\n",
    "    data_df_test = shuffle(data_df_test, random_state=m_random_state)\n",
    "    data_df_train = shuffle(data_df_train, random_state=m_random_state)\n",
    "    return data_df_train,data_df_test     \n",
    "    \n",
    "#######################################################################################\n",
    "##############            Machine learning algorithms                      ############\n",
    "#######################################################################################\n",
    "\n",
    "# logistic regression\n",
    "def log_reg_classifier(imgs_features, imgs_lbls, c=1):\n",
    "    \"\"\"\n",
    "    input - list of featurs list\n",
    "    output - logistic regression classifier\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(C = c, penalty = 'l2') #TODO check best C\n",
    "    return clf.fit(imgs_features, imgs_lbls)\n",
    "\n",
    "# SVM\n",
    "def svm_classifier(imgs_features, imgs_lbls, c=1):\n",
    "    \"\"\"\n",
    "    input - list of featurs list\n",
    "    output - svm classifier\n",
    "    \"\"\"\n",
    "    # Create a classifier: a support vector classifier\n",
    "    svm_classifier = svm.SVC(C = c) #TODO check best C\n",
    "    # training\n",
    "    return svm_classifier.fit(imgs_features, imgs_lbls)\n",
    "    \n",
    "# KNN\n",
    "def knn_classifier(imgs_features, imgs_lbls, k=1):\n",
    "    \"\"\"\n",
    "    input - list of featurs list\n",
    "    output - knn classifier\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors = k) #TODO check best k\n",
    "    return knn.fit(imgs_features, imgs_lbls) \n",
    "    \n",
    "    \n",
    "\n",
    "#######################################################################################\n",
    "##############            TESTS                                            ############\n",
    "#######################################################################################\n",
    "        \n",
    "def test_images_flow(inputFolder):\n",
    "    #1. extract facial landmarks\n",
    "    t1 = time.time()\n",
    "    images_landmarks = extract_dlib_facial_points(inputFolder)\n",
    "    print(\"landmarks shape: \", str(images_landmarks.shape))\n",
    "    #2. extract features df\n",
    "    t2 = time.time()\n",
    "    df = extract_features_forall(images_landmarks)\n",
    "    print(\"features shape: \", str(df.shape))\n",
    "    #print(df)\n",
    "    #3. using correlation matrix to reduce dimension\n",
    "    t3 = time.time()\n",
    "    corrDf = reduce_correlated_cols(df)\n",
    "    print(\"corr df shape: \", str(corrDf.shape))\n",
    "    #4. reduce dimension with PCA\n",
    "    t4 = time.time()\n",
    "    m_pca = dimension_reduction_pca(corrDf, 150)\n",
    "    t5 = time.time()\n",
    "    #timing report:\n",
    "    print(\"Timing Report:\")\n",
    "    print(\"Extract landmarks:\" + str(t2-t1))\n",
    "    print(\"Extract features:\" + str(t3-t2))\n",
    "    print(\"Extract correlation:\" + str(t4-t3))\n",
    "    print(\"Extract pca:\" + str(t5-t4))\n",
    "    return corrDf, m_pca\n",
    "\n",
    "def test_ml_algos_on_ck(inputFolderCKData):\n",
    "    print(\"Start testing...\")\n",
    "    (facial_landmarks_data, train_lbls) = dataset_from_ck(inputFolderCKData)\n",
    "    features_df = extract_features_forall(facial_landmarks_data)\n",
    "    #reduce dimensions\n",
    "    print(\"Dim reduction...\")\n",
    "    pca = dimension_reduction_pca(features_df, 500)\n",
    "    features_red = pca.transform(features_df)\n",
    "    #training ml algos\n",
    "    print(\"ml algos training...\")\n",
    "    m_knn = knn_classifier(features_red,train_lbls,3)\n",
    "    m_svm = svm_classifier(features_red,train_lbls)\n",
    "    m_log_reg = log_reg_classifier(features_red,train_lbls)\n",
    "    #test ml algos\n",
    "    print(\"KNN -  score on training data: \", m_knn.score(features_red,train_lbls))\n",
    "    print(\"SVM -  score on traifeatures_df = extract_features_forall(facial_landmarks_data)ning data: \", m_svm.score(features_red, train_lbls))\n",
    "    print(\"Logistic Regression - score on training data: \", m_log_reg.score(features_red,train_lbls))\n",
    "\n",
    "def find_best_params(inputFolderCKData):\n",
    "    scoresSVM = []\n",
    "    scoresLogReg = []\n",
    "    scoresKNN = []\n",
    "    print(\"Start testing...\")\n",
    "    (facial_landmarks_data, facial_landmarks_lbls) = dataset_from_ck(inputFolderCKData)\n",
    "    facial_landmarks_lbls = np.array(facial_landmarks_lbls)\n",
    "    features_df = extract_features_forall(facial_landmarks_data)\n",
    "    image_num = len(facial_landmarks_lbls)\n",
    "    #reduce dimensions\n",
    "    print(\"Dim reduction...\")\n",
    "    pca = dimension_reduction_pca(features_df, 1600)\n",
    "    features_red = pca.transform(features_df)\n",
    "    #dividing to train and validation\n",
    "    randIndxs = list(range(image_num))\n",
    "    random.shuffle(randIndxs)\n",
    "    train_data = features_red[randIndxs[:image_num//2]]\n",
    "    train_lbls = facial_landmarks_lbls[randIndxs[:image_num//2]]\n",
    "    validation_data = features_red[randIndxs[image_num//2:]]\n",
    "    validation_lbls = facial_landmarks_lbls[randIndxs[image_num//2:]]\n",
    "    #training ml algos\n",
    "    Cs = [10**i for i in range(-10,11)]\n",
    "    Ks = list(range(1,11))\n",
    "    #train C:\n",
    "    print(\"svm & logreg C algos training...\")\n",
    "    for c in Cs:\n",
    "        m_svm = svm_classifier(train_data,train_lbls, c)\n",
    "        scoresSVM.append(m_svm.score(validation_data,validation_lbls))\n",
    "        m_log_reg = log_reg_classifier(train_data,train_lbls,c)\n",
    "        scoresLogReg.append(m_log_reg.score(validation_data,validation_lbls))\n",
    "    #train K:\n",
    "    print(\"KNN K algos training...\")\n",
    "    for k in Ks:\n",
    "        m_knn = knn_classifier(train_data,train_lbls,k)\n",
    "        scoresKNN.append(m_knn.score(validation_data,validation_lbls))\n",
    "    save_plt_scores(Cs,\"C\",scoresSVM, \"SVM scores\",\"SVM scores as a function of C (on vaildation data)\")\n",
    "    save_plt_scores(Cs,\"C\",scoresLogReg, \"Logistic Regression scores\",\"Logistic Regression scores as a function of C (on vaildation data)\")\n",
    "    save_plt_scores(Ks,\"K\",scoresKNN, \"KNN scores\",\"KNN scores as a function of K (on vaildation data)\", False)\n",
    "\n",
    "def test_train_times(inputFolderCKData):\n",
    "    timesSVM = []\n",
    "    timesLogReg = []\n",
    "    timesKNN = []\n",
    "    print(\"Start testing...\")\n",
    "    (facial_landmarks_data, facial_landmarks_lbls) = dataset_from_ck(inputFolderCKData)\n",
    "    facial_landmarks_lbls = np.array(facial_landmarks_lbls)\n",
    "    features_df = extract_features_forall(facial_landmarks_data)\n",
    "    Ds = [i for i in range(100, 1600, 100)]\n",
    "    print(\"Measuring times...\")\n",
    "    for d in Ds:\n",
    "        pca = dimension_reduction_pca(features_df, d)\n",
    "        features_red = pca.transform(features_df)\n",
    "        t1 = time.time()\n",
    "        svm_classifier(features_red,facial_landmarks_lbls)\n",
    "        t2 = time.time()\n",
    "        log_reg_classifier(features_red,facial_landmarks_lbls)\n",
    "        t3 = time.time()\n",
    "        knn_classifier(features_red,facial_landmarks_lbls)\n",
    "        t4 = time.time()\n",
    "        timesSVM.append(t2-t1)\n",
    "        timesLogReg.append(t3-t2)\n",
    "        timesKNN.append(t4-t3)\n",
    "    # timesSVM = np.array(timesSVM) / len(features_red)\n",
    "    # timesLogReg = np.array(timesLogReg) / len(features_red)\n",
    "    # timesKNN = np.array(timesKNN) / len(features_red)\n",
    "    save_plt_scores(Ds,\"d\",timesSVM, \"SVM train time\",\"SVM train time as a function of d\", False)\n",
    "    save_plt_scores(Ds,\"d\",timesLogReg, \"Logistic Regression train time\",\"Logistic Regression train time as a function of d\", False)\n",
    "    save_plt_scores(Ds,\"d\",timesKNN, \"KNN train time\",\"KNN train time as a function of d\", False)\n",
    "\n",
    "def plot_3_principal_components(inputFolderCKData):\n",
    "    plot_title = \"3 Principal Components Scatter\"\n",
    "    colors_dict = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple', 5:'tab:brown', 6:'tab:pink', 7:'tab:gray', 8:'tab:olive', 9:'tab:cyan'}\n",
    "    (facial_landmarks_data, facial_landmarks_lbls) = dataset_from_ck(inputFolderCKData)\n",
    "    facial_landmarks_lbls = np.array(facial_landmarks_lbls)\n",
    "    features_df = extract_features_forall(facial_landmarks_data)\n",
    "    pca = dimension_reduction_pca(features_df, 3)\n",
    "    features_red = pca.transform(features_df)\n",
    "    features_red = features_red.transpose()\n",
    "    colors = np.array([colors_dict[x] for x in facial_landmarks_lbls])\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(features_red[0], features_red[1], features_red[2], c=colors)\n",
    "    fig.savefig(plot_title+'.png')\n",
    "\n",
    "\n",
    "def test_train_NN_times(inputFolderCKData):\n",
    "    print(\"Start testing...\")\n",
    "    (facial_landmarks_data, facial_landmarks_lbls) = dataset_from_ck(inputFolderCKData)\n",
    "    facial_landmarks_lbls = np.array(facial_landmarks_lbls)\n",
    "    features_df = extract_features_forall(facial_landmarks_data)\n",
    "    features_df[\"expression\"] = facial_landmarks_lbls\n",
    "    for i in range(len(EMOTIONS)):\n",
    "        features_df[\"is_{0:s}\".format(EMOTIONS[i])] = (features_df[\"expression\"] == i)\n",
    "    features_df = features_df.drop(\"expression\", axis=1)\n",
    "    #features_df.to_csv(\"face.csv\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "##############            RUN                                              ############\n",
    "#######################################################################################\n",
    "    \n",
    "#test_images_flow(r\"C:\\Users\\DELL1\\Documents\\studies\\FinalProject\\facial-landmarks\\facial-landmarks\\images\")\n",
    "#test_ml_algos_on_ck(r\"C:\\Users\\DELL1\\Documents\\studies\\FinalProject\\Datatsets\\CK+\\sorted_set\")\n",
    "#plot_3_principal_components(r\"C:\\Santos\\TAU\\Final\\Datasets\\CK+\\sorted_set - CK+\")\n",
    "#sort_sample_affectnet(r\"C:\\Users\\DELL1\\Documents\\studies\\FinalProject\\Datatsets\\AffectNet\\Manually_Annotated\\FirstTrain\", r\"C:\\Users\\DELL1\\Documents\\studies\\FinalProject\\Datatsets\\AffectNet\\\\Manually_Annotated\\FirstTrain.csv\")\n",
    "#csv_to_features(r\"C:\\Users\\Santos\\Documents\\GitHub\\ExpressionRecognition\\FirstTrain\\out.csv\")\n",
    "print(\"test syntax passed:)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing affectnet_landmarks_0.csv\n",
      "Processing affectnet_landmarks_1.csv\n",
      "Processing affectnet_landmarks_2.csv\n",
      "Processing affectnet_landmarks_3.csv\n",
      "Processing affectnet_landmarks_4.csv\n",
      "Processing affectnet_landmarks_5.csv\n",
      "Processing affectnet_landmarks_6.csv\n",
      "Processing affectnet_landmarks_7.csv\n"
     ]
    }
   ],
   "source": [
    "csv_to_features(\".//Affectnet//\", filePrefix=\"affectnet_landmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPaths = [\".//Affectnet//features_affectnet_landmarks_{0}.csv\".format(str(i)) for i in range(8)]\n",
    "train_df,test_df = prepare_balanced_data(csvPaths, 2000)\n",
    "#process to workable dfs\n",
    "X_train = train_df.iloc[:, :-8].as_matrix()    #data\n",
    "Y_oh_train = train_df.iloc[:, -8:]             #labels\n",
    "X_test = test_df.iloc[:, :-8].as_matrix()      #data\n",
    "Y_oh_test = test_df.iloc[:, -8:]               #labels\n",
    "Y_train = sum(i*Y_oh_train.iloc[:, i] for i in range(8))\n",
    "Y_test = sum(i*Y_oh_train.iloc[:, i] for i in range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logistic_reg(X_train, Y_train, X_test, Y_test, C = 0.1):\n",
    "    m_log_reg = log_reg_classifier(X_train,Y_train,C)\n",
    "    print(\"LogisticRegression score is: {}\".format(m_log_reg.score(X_test,Y_test)))\n",
    "    return m_log_reg\n",
    "def get_KNN(X_train, Y_train, X_test, Y_test, K = 3):\n",
    "    m_knn = knn_classifier(X_train,Y_train,K)\n",
    "    print(\"KNN score is: {}\".format(m_knn.score(X_test,Y_test)))\n",
    "    return m_knn\n",
    "def get_SVM(X_train, Y_train, X_test, Y_test, C = 1):\n",
    "    m_svm = svm_classifier(X_train,Y_train,C)\n",
    "    print(\"SVM score is: {}\".format(m_svm.score(X_test,Y_test)))\n",
    "    return m_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 6552)\n",
      "(14400,)\n",
      "(1600, 6552)\n",
      "(14400,)\n"
     ]
    }
   ],
   "source": [
    "#m_log = get_logistic_reg(X_train, Y_train, X_test, Y_test)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_log_reg = log_reg_classifier(X_train,Y_train,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
